{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42c33916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9189b6a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m.read_csv(\u001b[33m\"\u001b[39m\u001b[33m./../Data/IMDB_Dataset.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      2\u001b[39m df.head()\n",
      "\u001b[31mNameError\u001b[39m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./../Data/IMDB_Dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c855ab",
   "metadata": {},
   "source": [
    "#### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b65d42ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one of the other reviewers has mentioned that ...\n",
       "1    a wonderful little production. <br /><br />the...\n",
       "2    i thought this was a wonderful way to spend ti...\n",
       "3    basically there's a family where a little boy ...\n",
       "4    petter mattei's \"love in the time of money\" is...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].str.lower()\n",
    "df['review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f59ff8",
   "metadata": {},
   "source": [
    "#### Remove HTML tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed08622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bdb3fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Shawshank Redemption (1994) - IMDb Rating: 9.3/10\n"
     ]
    }
   ],
   "source": [
    "text = '<div><strong>The Shawshank Redemption</strong> (1994) - IMDb Rating: <span style=\"color:goldenrod;\">9.3/10</span></div>'\n",
    "print(remove_html_tags(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99da26ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one of the other reviewers has mentioned that ...\n",
       "1    a wonderful little production. the filming tec...\n",
       "2    i thought this was a wonderful way to spend ti...\n",
       "3    basically there's a family where a little boy ...\n",
       "4    petter mattei's \"love in the time of money\" is...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'] = df['review'].apply(remove_html_tags)\n",
    "df['review'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff10c535",
   "metadata": {},
   "source": [
    "#### Remove URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9cf846c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check out the youtube link \n",
      "click on the given link \n"
     ]
    }
   ],
   "source": [
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "text1 = \"check out the youtube link https://www.youtube.com\"\n",
    "text2 = \"click on the given link https://www.gmail.com\"\n",
    "\n",
    "print(remove_url(text1))\n",
    "print(remove_url(text2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43be17af",
   "metadata": {},
   "source": [
    "#### Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0f3ebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey how are you  ssadas\n",
      "Where are you When you will come asdsa\n",
      "15.652179718017578\n"
     ]
    }
   ],
   "source": [
    "import string,time\n",
    "spl_char = string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    for char in text:\n",
    "        if char in spl_char:\n",
    "            text = text.replace(char,\"\")\n",
    "    return text\n",
    "\n",
    "text1 = \"Hey, how are you...!!! ^%& ssadas\"\n",
    "text2 = \"Where are you? When you will come#$@ asdsa\"\n",
    "\n",
    "start_time = time.time()\n",
    "print(remove_punctuation(text1))\n",
    "print(remove_punctuation(text2))\n",
    "end_time = time.time() - start_time\n",
    "print((end_time)*50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b8c0f5",
   "metadata": {},
   "source": [
    "#### Alternate Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7f2d9f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey how are you  ssadas\n",
      "Where are you When you will come asdsa\n",
      "484.7288131713867\n"
     ]
    }
   ],
   "source": [
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('','',spl_char))\n",
    "\n",
    "text1 = \"Hey, how are you...!!! ^%& ssadas\"\n",
    "text2 = \"Where are you? When you will come#$@ asdsa\"\n",
    "\n",
    "start_time = time.time()\n",
    "print(remove_punc(text1))\n",
    "print(remove_punc(text2))\n",
    "end_time = time.time() - start_time\n",
    "print((end_time)*50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2a845",
   "metadata": {},
   "source": [
    "#### Chat Conversation Handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd2a0d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can you update the status As soon as possible'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words = {\n",
    "    \"ASAP\": \"As soon as possible\",\n",
    "    \"BRB\": \"Be right back\",\n",
    "    \"BTW\": \"By the way\",\n",
    "    \"DIY\": \"Do it yourself\",\n",
    "    \"FYI\": \"For your information\",\n",
    "    \"GTG\": \"Got to go\",\n",
    "    \"IDK\": \"I don't know\",\n",
    "    \"IMO\": \"In my opinion\",\n",
    "    \"IMHO\": \"In my humble opinion\",\n",
    "    \"LOL\": \"Laughing out loud\",\n",
    "    \"OMG\": \"Oh my God\",\n",
    "    \"ROFL\": \"Rolling on the floor laughing\",\n",
    "    \"TBH\": \"To be honest\",\n",
    "    \"TTYL\": \"Talk to you later\",\n",
    "    \"TTYS\": \"Talk to you soon\",\n",
    "    \"WYD\": \"What are you doing\",\n",
    "    \"YOLO\": \"You only live once\",\n",
    "    \"ILY\": \"I love you\",\n",
    "    \"SMH\": \"Shaking my head\",\n",
    "    \"TMI\": \"Too much information\",\n",
    "    \"NVM\": \"Never mind\",\n",
    "    \"IDC\": \"I don't care\",\n",
    "    \"BFF\": \"Best friends forever\",\n",
    "    \"JK\": \"Just kidding\",\n",
    "    \"LMK\": \"Let me know\",\n",
    "    \"RN\": \"Right now\",\n",
    "    \"ICYMI\": \"In case you missed it\",\n",
    "    \"OOTD\": \"Outfit of the day\",\n",
    "    \"NSFW\": \"Not safe for work\",\n",
    "    \"FOMO\": \"Fear of missing out\"\n",
    "}\n",
    "\n",
    "def chat_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words:\n",
    "            new_text.append(chat_words[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "chat_conversion(\"Can you update the status ASAP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5d17f4",
   "metadata": {},
   "source": [
    "#### Incorrect Text Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bba8045f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello are you coming for the trip next weekend'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "mispelled_text = \"Hello arre you cominggg for thes trip nextu weekund\"\n",
    "textblob = TextBlob(mispelled_text)\n",
    "textblob.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc498161",
   "metadata": {},
   "source": [
    "#### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3cb150be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\balaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d6bc2d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    one reviewers mentioned watching 1 oz episode ...\n",
       "1    wonderful little production. filming technique...\n",
       "2    thought wonderful way spend time hot summer we...\n",
       "3    basically there's family little boy (jake) thi...\n",
       "4    petter mattei's \"love time money\" visually stu...\n",
       "5    probably all-time favorite movie, story selfle...\n",
       "6    sure would like see resurrection dated seahunt...\n",
       "7    show amazing, fresh & innovative idea 70's fir...\n",
       "8    encouraged positive comments film looking forw...\n",
       "9    like original gut wrenching laughter like movi...\n",
       "Name: review, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word not in stopwords.words('english'):\n",
    "            new_text.append(word)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "df['review'] = df['review'][:10].apply(remove_stopwords)\n",
    "df['review'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f976ffd0",
   "metadata": {},
   "source": [
    "#### Remove_Emoji Handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a97d2385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hey its running  time out '"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def remove_emoji(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                                u\"\\U0001F600-\\U0001F64F\"\n",
    "                                u\"\\U0001F300-\\U0001F5FF\"\n",
    "                                u\"\\U0001F680-\\U0001F6FF\"\n",
    "                                u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                                u\"\\U00002702-\\U000027B0\"\n",
    "                                u\"\\U000024C2-\\U0001F251\"\n",
    "                                \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'',text)\n",
    "\n",
    "text1 = \" Hey its running ❤️ time out 😂\"\n",
    "remove_emoji(text1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2e2de9a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Downloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "   ---------------------------------------- 0.0/590.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 590.6/590.6 kB 3.0 MB/s eta 0:00:00\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-2.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cb94d11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best friends forever :people_with_bunny_ears:\n",
      "Not safe for work :prohibited:\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "print(emoji.demojize(\"Best friends forever 👯\"))\n",
    "print(emoji.demojize(\"Not safe for work 🚫\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d16d73",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77f1921",
   "metadata": {},
   "source": [
    "##### 1. Using the split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76d0da62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "sent1 = \"I am going to delhi\"\n",
    "sent1.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d1989f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I am going to delhi', ' And planning to get job in Data Science']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "sent2 = \"I am going to delhi. And planning to get job in Data Science\"\n",
    "sent2.split('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a019382b",
   "metadata": {},
   "source": [
    "##### Problems with split function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "0518841f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'going', 'to', 'delhi!']\n",
      "['where do think I should go? I have 3 day holiday']\n"
     ]
    }
   ],
   "source": [
    "sent3 = 'I am going to delhi!'\n",
    "print(sent3.split())\n",
    "\n",
    "sent4 = 'where do think I should go? I have 3 day holiday'\n",
    "print(sent4.split('.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931bff58",
   "metadata": {},
   "source": [
    "##### 2. Regular Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "87da7bd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'going', 'to', 'delhi']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "sent5 = 'I am going to delhi!'\n",
    "tokens = re.findall(r\"[\\w']+\", sent5)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "9497060b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\nThe old clock struck midnight as Mia stepped into the attic',\n",
       " ' A dusty journal lay open, its pages fluttering despite the still air,\\nShe read a name & her own written decades ago in shaky ink',\n",
       " '\\nSuddenly, the lights flickered, and a whisper called her back',\n",
       " '\\nMia smiled $ she had finally found the secret her grandmother left behind',\n",
       " '\\n']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent6 =\"\"\"\n",
    "The old clock struck midnight as Mia stepped into the attic? A dusty journal lay open, its pages fluttering despite the still air,\n",
    "She read a name & her own written decades ago in shaky ink!\n",
    "Suddenly, the lights flickered, and a whisper called her back.\n",
    "Mia smiled $ she had finally found the secret her grandmother left behind.\n",
    "\"\"\"\n",
    "sentences = re.compile('[.!?]').split(sent6)\n",
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4b84d0",
   "metadata": {},
   "source": [
    "#### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "421a2ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\balaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "34830745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T', 'am', 'going', 'to', 'visit', 'Delhi', '!']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent7 = \"T am going to visit Delhi!\"\n",
    "word_tokenize(sent7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6e5d4776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hey Buddy, How are you ?', 'Can we go for a movie ?']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent8 = \"Hey Buddy, How are you ? Can we go for a movie ?\"\n",
    "sent_tokenize(sent8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19db23cf",
   "metadata": {},
   "source": [
    "#### NLTK SPACY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "408c401c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The old clock struck midnight as Mia stepped into the attic? A dusty journal lay open, its pages fluttering despite the still air,\n",
      "She read a name & her own written decades ago in shaky ink!\n",
      "Suddenly, the lights flickered, and a whisper called her back.\n",
      "Mia smiled $ she had finally found the secret her grandmother left behind.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "result = nlp(sent6)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b19db6",
   "metadata": {},
   "source": [
    "#### Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "87905452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'walk walk walk walk'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])\n",
    "\n",
    "sample = \"walks walk walking walked\"\n",
    "stem_words(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b0b7a7",
   "metadata": {},
   "source": [
    "#### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c3b325b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\balaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\balaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'was',\n",
       " 'running',\n",
       " 'and',\n",
       " 'eating',\n",
       " 'at',\n",
       " 'same',\n",
       " 'time',\n",
       " 'He',\n",
       " 'has',\n",
       " 'bad',\n",
       " 'habit',\n",
       " 'of',\n",
       " 'swimming',\n",
       " 'after',\n",
       " 'playing']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "wordnet = WordNetLemmatizer()\n",
    "\n",
    "sentence = \"He was running and eating at same time. He has bad habit of swimming after playing \"\n",
    "punctuations = \"?:!.,;\"\n",
    "sentence_words = nltk.word_tokenize(sentence)\n",
    "for word in sentence_words:\n",
    "    if word in punctuations:\n",
    "        sentence_words.remove(word)\n",
    "\n",
    "sentence_words\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
